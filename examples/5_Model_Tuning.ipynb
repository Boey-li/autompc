{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning\n",
    "\n",
    "This notebook will demonstate how to automatically tune model hyperparameters for prediction accuracy.\n",
    "\n",
    "## Set-Up\n",
    "We will begin with some imports and then generate some training data using the simple cart-pole benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/randomgraph/baoyul2/meta/autompc')\n",
    "import autompc as ampc\n",
    "import numpy as np\n",
    "\n",
    "from autompc.benchmarks import CartpoleSwingupBenchmark, CartpoleSwingupV2Benchmark\n",
    "\n",
    "# benchmark = CartpoleSwingupBenchmark()\n",
    "benchmark = CartpoleSwingupV2Benchmark()\n",
    "\n",
    "system = benchmark.system\n",
    "trajs = benchmark.gen_trajs(seed=100, n_trajs=100, traj_len=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, AutoMPC's `ModelTuner` will auto-select from all available models to fit the trajectories as best as possible. The tuner by default will run for 10 iterations, but for real problems you will want to run for many, many more iterations (100s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is used for GPytorch\n",
      "Selecting from models MLP,ARX,Koopman,SINDy,ApproximateGPModel\n",
      "Evaluating Cfg:\n",
      "Configuration(values={\n",
      "  'MLP:batchnorm': False,\n",
      "  'MLP:hidden_size_1': 128,\n",
      "  'MLP:hidden_size_2': 128,\n",
      "  'MLP:lr': 0.001,\n",
      "  'MLP:n_hidden_layers': '2',\n",
      "  'MLP:nonlintype': 'relu',\n",
      "  'model': 'MLP',\n",
      "})\n",
      "\n",
      "Seed 0 budget 0.0\n",
      "100%|██████████| 200/200 [00:56<00:00,  3.57it/s]\n",
      "100%|██████████| 200/200 [00:56<00:00,  3.56it/s]\n",
      "100%|██████████| 200/200 [00:55<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_iter must be positive\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/randomgraph/anaconda3/envs/meta/lib/python3.9/site-packages/smac/tae/execute_func.py\", line 217, in run\n",
      "    rval = self._call_ta(self._ta, config, obj_kwargs)\n",
      "  File \"/home/randomgraph/anaconda3/envs/meta/lib/python3.9/site-packages/smac/tae/execute_func.py\", line 314, in _call_ta\n",
      "    return obj(config, **obj_kwargs)\n",
      "  File \"/home/randomgraph/baoyul2/meta/autompc/autompc/tuning/model_tuner.py\", line 120, in _evaluate\n",
      "    value = self.evaluator(self.model)\n",
      "  File \"/home/randomgraph/baoyul2/meta/autompc/autompc/tuning/model_evaluator.py\", line 160, in __call__\n",
      "    m.train(train)\n",
      "  File \"/home/randomgraph/baoyul2/meta/autompc/autompc/sysid/autoselect.py\", line 68, in train\n",
      "    self.selected_model.train(trajs)\n",
      "  File \"/home/randomgraph/baoyul2/meta/autompc/autompc/sysid/sindy.py\", line 160, in train\n",
      "    self._init_model()\n",
      "  File \"/home/randomgraph/baoyul2/meta/autompc/autompc/sysid/sindy.py\", line 156, in _init_model\n",
      "    optimizer=ps.STLSQ(threshold=self.threshold, max_iter=max_iter))\n",
      "  File \"/home/randomgraph/anaconda3/envs/meta/lib/python3.9/site-packages/pysindy/optimizers/stlsq.py\", line 90, in __init__\n",
      "    super(STLSQ, self).__init__(\n",
      "  File \"/home/randomgraph/anaconda3/envs/meta/lib/python3.9/site-packages/pysindy/optimizers/base.py\", line 72, in __init__\n",
      "    raise ValueError(\"max_iter must be positive\")\n",
      "ValueError: max_iter must be positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score  0.017887528491952753\n",
      "Evaluating Cfg:\n",
      "Configuration(values={\n",
      "  'SINDy:poly_basis': 'true',\n",
      "  'SINDy:poly_cross_terms': 'false',\n",
      "  'SINDy:poly_degree': 3,\n",
      "  'SINDy:threshold': 0.03240796443598578,\n",
      "  'SINDy:time_mode': 'discrete',\n",
      "  'SINDy:trig_basis': 'true',\n",
      "  'SINDy:trig_freq': 7,\n",
      "  'SINDy:trig_interaction': 'false',\n",
      "  'model': 'SINDy',\n",
      "})\n",
      "\n",
      "Seed 0 budget 0.0\n",
      "100%|██████████| 200/200 [01:23<00:00,  2.40it/s]\n",
      "Selected model: MLP\n",
      "Final cross-validated RMSE score: 0.017887528491952753\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from autompc.tuning import ModelTuner\n",
    "\n",
    "tuner = ModelTuner(system,trajs,verbose=1)\n",
    "print(\"Selecting from models\",\",\".join(model.name for model in tuner.model.models))\n",
    "tuned_model,tune_result = tuner.run(n_iters=2)\n",
    "\n",
    "print(\"Selected model:\",tuned_model.name)\n",
    "print(\"Final cross-validated RMSE score:\",tune_result.inc_costs[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can customize the behavior of tuning by specifying which evaluation strategy we wish to use.  Possible options include splitting method (holdout vs cross-validation), which horizon to measure predictions upon, and what scoring metric to use.  By default, ModelTuner uses 3-fold cross-validation and one-step RMSE.\n",
    "\n",
    "Here's an example of customizing the evaluator to use with 10\\% holdout and the RMSE metric with a 5-step prediction horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = ModelTuner(system,trajs,eval_holdout=0.1,eval_folds=1,eval_metric='rmse',eval_horizon=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To customize behavior even further, we can use a `ModelEvaluator` class, which has various subclasses.  As an example, the HoldoutModelEvaluator is specified here.  The `evaluator` keyword to ModelTuner will specify an evaluator that overrides the default keyword arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autompc.tuning import HoldoutModelEvaluator\n",
    "\n",
    "evaluator = HoldoutModelEvaluator(trajs, metric=\"rmse\", holdout_prop=0.1,\n",
    "                                  rng=np.random.default_rng(100), horizon=20)\n",
    "tuner = ModelTuner(system,trajs,evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying the Model Class\n",
    "\n",
    "In some cases we know which model class we wish to tune, and ModelTuner can also accept a specified class.  For example, we can consider the MLP model. Here we'll perform a much longer tuning run, so let this run for a few hours...\n",
    "\n",
    "**Alternatively, you can save/load the tuning data from a prior run by setting `dump=False` in the following cell, and skipping the tuning altogether.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from autompc.sysid import MLP\n",
    "\n",
    "tuner = ModelTuner(system,trajs,MLP(system),verbose=True)\n",
    "tuned_model, tune_result = tuner.run(n_iters=200,rng=np.random.default_rng(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#To dump tuning result, turn to True.  To load it, turn to False\n",
    "DUMP = False\n",
    "if DUMP:\n",
    "    with open('tuned_mlp_model.pkl','wb') as f:\n",
    "        pickle.dump(tuned_model,f)\n",
    "    with open('mlp_model_tuning_result.pkl','wb') as f:\n",
    "        pickle.dump(tune_result,f)\n",
    "else:\n",
    "    with open('tuned_mlp_model.pkl','rb') as f:\n",
    "        tuned_model = pickle.load(f)\n",
    "    with open('mlp_model_tuning_result.pkl','rb') as f:\n",
    "        tune_result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what configuration was selected by the tuner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_result.inc_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the tuner selected a 2-layer MLP with `tanh` activations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on, let's note that another option is to specify a set of model classes to use. To do so we can use the AutoSelectModel class as the model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autompc.sysid import SINDy\n",
    "from autompc.sysid import AutoSelectModel\n",
    "\n",
    "selector = AutoSelectModel(system,[MLP(system),SINDy(system)])\n",
    "tuner = ModelTuner(system,trajs,model=selector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Results\n",
    "\n",
    "We can now visualize the tuning results.  First, we will plot the tuning curve.  This shows the holdout set performance of the best-known model at different points over the course of the tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from autompc.graphs import plot_tuning_curve,plot_tuning_correlations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_tuning_curve(tune_result)\n",
    "plt.title(\"Cart-Pole Tuning Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further study the tuning, we can examine how the cost correlates with various hyperparameter settings using the `plot_tuning_correlations` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(15,4))\n",
    "plot_tuning_correlations(tune_result,'lr',ax=ax1)\n",
    "plot_tuning_correlations(tune_result,'n_hidden_layers',ax=ax2)\n",
    "plot_tuning_correlations(tune_result,'nonlintype',ax=ax3)\n",
    "ax1.set_ylim(0,1.5)\n",
    "ax2.set_ylim(0,1.5)\n",
    "ax3.set_ylim(0,3.0)\n",
    "ax3.set_title('nonlintype')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can compare the performance of our tuned model to the default MLP configuration.  We will generate a fresh dataset for testing and compare over multiple prediction horizons.  For more details on how to do this comparison, see [2. Models]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untuned_model = MLP(system)\n",
    "untuned_model.train(trajs)\n",
    "\n",
    "testing_set = benchmark.gen_trajs(seed=101, n_trajs=100, traj_len=200)\n",
    "\n",
    "from autompc.graphs.kstep_graph import KstepPredAccGraph\n",
    "\n",
    "graph = KstepPredAccGraph(system, testing_set, kmax=20, metric=\"rmse\")\n",
    "graph.add_model(untuned_model, \"Untuned MLP\")\n",
    "graph.add_model(tuned_model, \"Tuned Model (MLP)\")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "graph(fig, ax)\n",
    "ax.set_title(\"Model prediction accuracy on test set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the tuned model outperforms the untuned model on the unseen dataset at all prediction horizons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = KstepPredAccGraph(system, trajs, kmax=20, metric=\"rmse\")\n",
    "graph.add_model(untuned_model, \"Untuned MLP\")\n",
    "graph.add_model(tuned_model, \"Tuned Model (MLP)\")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "graph(fig, ax)\n",
    "ax.set_title(\"Model prediction accuracy on training set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('meta')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b3c234624630e949b531b97175f47faedff7f0122e4bda473deb0f08dcf222b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

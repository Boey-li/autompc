{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning\n",
    "\n",
    "This notebook will demonstrate how to do tuning for models and controllers.\n",
    "\n",
    "## Set-Up\n",
    "\n",
    "As always, we begin by obtaining our system, model, and task from the benchmarks package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autompc as ampc\n",
    "import numpy as np\n",
    "from autompc.benchmarks import CartpoleSwingupBenchmark\n",
    "\n",
    "benchmark = CartpoleSwingupBenchmark()\n",
    "\n",
    "# Get system and task specification\n",
    "system = benchmark.system\n",
    "task   = benchmark.task\n",
    "\n",
    "# Generate benchmark dataset\n",
    "trajs = benchmark.gen_trajs(seed=100, n_trajs=500, traj_len=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning\n",
    "\n",
    "First, we will demonstrate how to automatically tune the hyperparameters of a system ID model.\n",
    "\n",
    "First, we have to define the model evaluator, which handles the training and evaluation of individual model configurations.  Here, use the `HoldoutEvaluator` which randomly splits the dataset into a training set and holdout set for evaluation.  We will tune using the `RMSE` metric over a 20 step prediction horizon.  We also have to provide the evaluator with the trajectory dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autompc.evaluation import HoldoutModelEvaluator\n",
    "\n",
    "model_evaluator = HoldoutModelEvaluator(holdout_prop=0.25, metric=\"rmse\", horizon=20, trajs=trajs, \n",
    "                                        system=system, rng=np.random.default_rng(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to construct a model factory to tune. Model tuning also supports automatic model selection, so here will create two model factories to select between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autompc.sysid import MLPFactory, SINDyFactory\n",
    "\n",
    "model_factory_1 = MLPFactory(system)\n",
    "model_factory_2 = SINDyFactory(system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created our evaluator and our factories, we instantiate the `ModelTuner` and add both factories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autompc.tuning import ModelTuner\n",
    "\n",
    "model_tuner = ModelTuner(system, model_evaluator)\n",
    "model_tuner.add_model_factory(model_factory_1)\n",
    "model_tuner.add_model_factory(model_factory_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now run tuning for 100 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, model_tune_result = model_tuner.run(rng=np.random.default_rng(100), n_iters=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then plot the accuracy of the best model found so far over the course of the tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autompc.graphs import TuningCurveGraph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "graph = TuningCurveGraph()\n",
    "\n",
    "fig = plt.figure()      \n",
    "ax = fig.gca()\n",
    "graph(ax, model_tune_result)\n",
    "ax.set_title(\"Model Tuning Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Tuning\n",
    "\n",
    "Next, we will demonstrate how to do hyperparameter tuning for the entire MPC pipeline.  First, we create our factories and pipeline object. Here, we use an MLP system ID model, Iterative LQR control optimizer, and a quadratic cost.  AutoMPC does not currently support automatic selection of pipeline components, but we hope to add this feature soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autompc.control import IterativeLQRFactory\n",
    "from autompc.costs import QuadCostFactory\n",
    "\n",
    "\n",
    "ctrlr_factory = IterativeLQRFactory(system)\n",
    "cost_factory  = QuadCostFactory(system)\n",
    "model_factory = MLPFactory(system)\n",
    "\n",
    "pipeline = ampc.Pipeline(system, model_factory, cost_factory, ctrlr_factory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we instantiate the `PipelineTuner`.  AutoMPC performs tuning without access to the system dynamics, so the tuner has to train a surrogate dynamics model to use a simulator for controller evaluation.  In this example, we use an MLP surrogate model, so we pass in `MLPFactory`.  The `surrogate_split` tells what proportion of the data to use for surrogate training vs system ID training.  Here we use a 50/50 split.\n",
    "\n",
    "Finally, AutoMPC supports several methods of selecting the surrogate model, controller by the `surrogate_mode` argument.  Here we use `defaultcfg` which means the surrogate is trained using the default MLP configuration.  Other modes include `fixedcfg`, where the user specifies the surrogate configuration, `autotune`, where the tuner first tunes the surrogate factory before running the pipeline tuning, and `autoselect`, where the tuner both automatically selects the model type from the availble system ID algorithms and tunes the model hyperparameters.\n",
    "\n",
    "For more details on using these modes, see the [documentation](https://autompc.readthedocs.io/en/latest/source/tuning.html#pipelinetuner) for the `PipelineTuner` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autompc.tuning import PipelineTuner\n",
    "\n",
    "tuner = PipelineTuner(surrogate_factory=MLPFactory(system), surrogate_mode=\"defaultcfg\", surrogate_split=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created the tuner, we run it for 100 iterations.  We pass in the ground truth dynamics to keep track of the performance, but in a real application, we don't expect to have access to this, so this information is not used for tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller, tune_result = tuner.run(pipeline, task, trajs, n_iters=100, rng=np.random.default_rng(100), \n",
    "                                   truedyn=benchmark.dynamics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the tuning process, we can graph the performance of the best controller found so far, both with respect to the surrogate dynamics and the true dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autompc.graphs import TuningCurveGraph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "graph = TuningCurveGraph()\n",
    "\n",
    "fig = plt.figure()      \n",
    "ax = fig.gca()\n",
    "graph(ax, tune_result)\n",
    "ax.set_title(\"Cart-Pole Tuning Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoupled Tuning\n",
    "\n",
    "The above example is full pipeline tuning, which searches the configuration space of all components simultaneously.  Alternatively, we can take a decoupled tuning approach, where the model is first tuned based on prediction accuracy, then the objective function and optimizer are tuned.  Since full pipeline tuning requires us to train a system ID model and simulate the controller at every iteration, decoupled tuning may produce faster tuning.\n",
    "\n",
    "First, we'll need to handle the data split between system ID training set and surrogate training set manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(100)\n",
    "rng.shuffle(trajs)\n",
    "surr_trajs = trajs[:250]\n",
    "sysid_trajs = trajs[250:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we tune our system ID model for 75 iterations using the same model tuning method as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluator = HoldoutModelEvaluator(holdout_prop=0.25, metric=\"rmse\", horizon=20, trajs=sysid_trajs, \n",
    "                                        system=system, rng=np.random.default_rng(100))\n",
    "\n",
    "model_tuner = ModelTuner(system, model_evaluator)\n",
    "model_tuner.add_model_factory(model_factory)\n",
    "\n",
    "model, model_tune_result = model_tuner.run(rng=np.random.default_rng(100), n_iters=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we construct a new pipeline which fixes the model to be the result of the tuning process we just ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_fixed_model = ampc.Pipeline(system, model, ctrlr_factory, cost_factory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we run our pipeline tuning in a similar manner to above.  We now use tell the tuner to use 100% of data for tuning the surrogate, since we already handled the data split and did the system ID training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner2 = PipelineTuner(surrogate_factory=MLPFactory(system), surrogate_split=1.0)\n",
    "\n",
    "\n",
    "controller2, tune_result2 = tuner.run(pipeline_fixed_model, task, surr_trajs, n_iters=75, \n",
    "                                      rng=np.random.default_rng(100), truedyn=benchmark.dynamics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can plot the result of our decoupled pipeline tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autompc.graphs import TuningCurveGraph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "graph = TuningCurveGraph()\n",
    "\n",
    "fig = plt.figure()      \n",
    "ax = fig.gca()\n",
    "graph(ax, tune_result2)\n",
    "ax.set_title(\"Cart-Pole Decoupled Tuning Curve\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoMPC Demo\n",
    "\n",
    "Welcome!  This notebook demonstrates the core features of AutoMPC.  We will use the Cart-Pole swing-up task as an example, and we will tune an MPC pipeline consisting of a multi-layer perception (MLP) system ID model and an iLQR optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-Up\n",
    "\n",
    "To begin, we need an input dataset and specifications for the system and task.  The `benchmarks` module provides these for a few example systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing dependency for NMPC\n",
      "running build_ext\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "import autompc as ampc\n",
    "import numpy as np\n",
    "from autompc.benchmarks import CartpoleSwingupBenchmark\n",
    "\n",
    "benchmark = CartpoleSwingupBenchmark()\n",
    "\n",
    "\n",
    "# Get system and task specification\n",
    "system = benchmark.system\n",
    "task   = benchmark.task\n",
    "\n",
    "# Generate benchmark dataset\n",
    "trajs = benchmark.gen_trajs(seed=100, n_trajs=10, traj_len=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to declare our MPC pipeline.  The following code initializes a pipeline with a MLP system ID model, a quadratic objective function, and and an iLQR optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autompc.sysid import MLPFactory\n",
    "from autompc.control import IterativeLQRFactory\n",
    "from autompc.costs import QuadCostFactory\n",
    "\n",
    "model_factory = MLPFactory(system)\n",
    "ctrlr_factory = IterativeLQRFactory(system)\n",
    "cost_factory  = QuadCostFactory(system)\n",
    "\n",
    "pipeline = ampc.Pipeline(system, model_factory, ctrlr_factory, cost_factory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the joint configuration space of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Configuration space object:\n",
       "  Hyperparameters:\n",
       "    _cost:dx_F, Type: UniformFloat, Range: [0.001, 10000.0], Default: 1.0, on log-scale\n",
       "    _cost:dx_Q, Type: UniformFloat, Range: [0.001, 10000.0], Default: 1.0, on log-scale\n",
       "    _cost:omega_F, Type: UniformFloat, Range: [0.001, 10000.0], Default: 1.0, on log-scale\n",
       "    _cost:omega_Q, Type: UniformFloat, Range: [0.001, 10000.0], Default: 1.0, on log-scale\n",
       "    _cost:theta_F, Type: UniformFloat, Range: [0.001, 10000.0], Default: 1.0, on log-scale\n",
       "    _cost:theta_Q, Type: UniformFloat, Range: [0.001, 10000.0], Default: 1.0, on log-scale\n",
       "    _cost:u_R, Type: UniformFloat, Range: [0.001, 10000.0], Default: 1.0, on log-scale\n",
       "    _cost:x_F, Type: UniformFloat, Range: [0.001, 10000.0], Default: 1.0, on log-scale\n",
       "    _cost:x_Q, Type: UniformFloat, Range: [0.001, 10000.0], Default: 1.0, on log-scale\n",
       "    _ctrlr:horizon, Type: UniformInteger, Range: [5, 25], Default: 20\n",
       "    _model:hidden_size_1, Type: UniformInteger, Range: [16, 256], Default: 128\n",
       "    _model:hidden_size_2, Type: UniformInteger, Range: [16, 256], Default: 128\n",
       "    _model:hidden_size_3, Type: UniformInteger, Range: [16, 256], Default: 128\n",
       "    _model:hidden_size_4, Type: UniformInteger, Range: [16, 256], Default: 128\n",
       "    _model:lr, Type: UniformFloat, Range: [1e-05, 1.0], Default: 0.001, on log-scale\n",
       "    _model:n_hidden_layers, Type: Categorical, Choices: {1, 2, 3, 4}, Default: 2\n",
       "    _model:nonlintype, Type: Categorical, Choices: {relu, tanh, sigmoid, selu}, Default: relu\n",
       "  Conditions:\n",
       "    _model:hidden_size_2 | _model:n_hidden_layers in {'2', '3', '4'}\n",
       "    _model:hidden_size_3 | _model:n_hidden_layers in {'3', '4'}\n",
       "    _model:hidden_size_4 | _model:n_hidden_layers in {'4'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_configuration_space()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have initialized the pipeline and its factories, it is straightforward to set up a tuner to search the configuration space.  Here we use an MLP model for the surrogate model.  This is an example of full pipeline which searches the configuration space of all pipeline components simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/pyparsing.py:1745: FutureWarning: Possible set intersection at position 3\n",
      "  self.re = re.compile( self.reString )\n",
      "/home/william/.local/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda=True\n",
      "MLP Using Cuda\n",
      "hidden_sizes= [128, 128]\n",
      "100%|██████████| 50/50 [00:01<00:00, 28.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:smac.utils.io.cmd_reader.CMDReader:Output to smac3-output_2021-05-26_22:24:51_741247\n",
      "INFO:smac.facade.smac_hpo_facade.SMAC4HPO:Optimizing a deterministic scenario for quality without a tuner timeout - will make SMAC deterministic and only evaluate one configuration per iteration!\n",
      "INFO:smac.initial_design.sobol_design.SobolDesign:Running initial design for 25 configurations\n",
      "INFO:smac.facade.smac_hpo_facade.SMAC4HPO:<class 'smac.facade.smac_hpo_facade.SMAC4HPO'>\n",
      "INFO:smac.optimizer.smbo.SMBO:Running initial design\n",
      "INFO:smac.intensification.intensification.Intensifier:First run, no incumbent provided; challenger is assumed to be the incumbent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "use_cuda=True\n",
      "MLP Using Cuda\n",
      "hidden_sizes= [136, 136, 136]\n",
      "100%|██████████| 50/50 [00:02<00:00, 22.40it/s]\n",
      "Simulating Surrogate Trajectory: \n",
      " 25%|██▌       | 50/200 [00:02<00:07, 20.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:smac.tae.execute_func.ExecuteTAFuncDict:name 'numpy' is not defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/william/proj/autompc_dev/autompc/tuning/pipeline_tuner.py\", line 103, in eval_cfg\n",
      "    surr_traj = simulate(controller, task.get_init_obs(),\n",
      "  File \"/home/william/proj/autompc_dev/autompc/utils/simulation.py\", line 27, in simulate\n",
      "    u, constate = controller.run(constate, sim_traj[-1].obs)\n",
      "  File \"/home/william/proj/autompc_dev/autompc/control/ilqr.py\", line 593, in run\n",
      "    converged, states, ctrls, Ks, ks = self.compute_ilqr(new_obs, self._guess,\n",
      "  File \"/home/william/proj/autompc_dev/autompc/control/ilqr.py\", line 526, in compute_ilqr_default\n",
      "    ls_states[:, i + 1, :] = self.model.pred_batch(ls_states[:, i, :], ls_ctrls[:, i, :])\n",
      "  File \"/home/william/proj/autompc_dev/autompc/sysid/mlp.py\", line 230, in pred_batch\n",
      "    return state + dy.reshape((state.shape[0], self.state_dim))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/william/.local/lib/python3.8/site-packages/smac/tae/execute_func.py\", line 207, in run\n",
      "    rval = self._call_ta(self._ta, config, obj_kwargs)\n",
      "  File \"/home/william/.local/lib/python3.8/site-packages/smac/tae/execute_func.py\", line 296, in _call_ta\n",
      "    return obj(config, **obj_kwargs)\n",
      "  File \"/home/william/proj/autompc_dev/autompc/tuning/pipeline_tuner.py\", line 115, in eval_cfg\n",
      "    except numpy.linalg.LinAlgError:\n",
      "NameError: name 'numpy' is not defined\n",
      "INFO:smac.stats.stats.Stats:##########################################################\n",
      "INFO:smac.stats.stats.Stats:Statistics:\n",
      "INFO:smac.stats.stats.Stats:#Incumbent changed: -1\n",
      "INFO:smac.stats.stats.Stats:#Submitted target algorithm runs: 1 / 100.0\n",
      "INFO:smac.stats.stats.Stats:#Finished target algorithm runs: 1 / 100.0\n",
      "INFO:smac.stats.stats.Stats:#Configurations: 1\n",
      "INFO:smac.stats.stats.Stats:Used wallclock time: 4.74 / inf sec \n",
      "INFO:smac.stats.stats.Stats:Used target algorithm runtime: 4.72 / inf sec\n",
      "INFO:smac.stats.stats.Stats:##########################################################\n",
      "INFO:smac.facade.smac_hpo_facade.SMAC4HPO:Final Incumbent: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FirstRunCrashedException",
     "evalue": "First run crashed, abort. Please check your setup -- we assume that your default configuration does not crashes. (To deactivate this exception, use the SMAC scenario option 'abort_on_first_run_crash'). Additional run info: {}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFirstRunCrashedException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6e1e30bf6cd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtuner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipelineTuner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurrogate_factory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMLPFactory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurrogate_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m controller, tune_result = tuner.run(pipeline, task, trajs, n_iters=100, rng=np.random.default_rng(100), \n\u001b[0m\u001b[1;32m      6\u001b[0m                                    truedyn=benchmark.dynamics)\n",
      "\u001b[0;32m~/proj/autompc_dev/autompc/tuning/pipeline_tuner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, pipeline, task, trajs, n_iters, rng, surrogate, truedyn, surrogate_tune_iters, special_debug)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 tae_runner=eval_cfg)\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0minc_cfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mcfgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_cfgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_costs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruedyn_costs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_truedyn_costs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurr_trajs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/smac/facade/smac_ac_facade.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0mincumbent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m             \u001b[0mincumbent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/smac/optimizer/smbo.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;31m# Add the results of the run to the run history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;31m# Additionally check for new incumbent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_incorporate_run_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared_model\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[attr-defined] # noqa F821\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/smac/optimizer/smbo.py\u001b[0m in \u001b[0;36m_incorporate_run_results\u001b[0;34m(self, run_info, result, time_left)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_on_first_run_crash\u001b[0m \u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[attr-defined] # noqa F821\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinished_ta_runs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mStatusType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCRASHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m                 raise FirstRunCrashedException(\n\u001b[0m\u001b[1;32m    478\u001b[0m                     \u001b[0;34m\"First run crashed, abort. Please check your setup -- we assume that your default \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                     \u001b[0;34m\"configuration does not crashes. (To deactivate this exception, use the SMAC scenario option \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFirstRunCrashedException\u001b[0m: First run crashed, abort. Please check your setup -- we assume that your default configuration does not crashes. (To deactivate this exception, use the SMAC scenario option 'abort_on_first_run_crash'). Additional run info: {}"
     ]
    }
   ],
   "source": [
    "from autompc.tuning import PipelineTuner\n",
    "\n",
    "tuner = PipelineTuner(surrogate_factory=MLPFactory(system), surrogate_split=0.5)\n",
    "\n",
    "controller, tune_result = tuner.run(pipeline, task, trajs, n_iters=100, rng=np.random.default_rng(100), \n",
    "                                   truedyn=benchmark.dynamics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is then easy to plot the curve from the tuning result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autompc.graphs import TuningCurveGraph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "graph = TuningCurveGraph()\n",
    "\n",
    "fig = plt.figure()      \n",
    "ax = fig.gca()\n",
    "graph(ax, tune_result)\n",
    "ax.set_title(\"Cart-Pole Tuning Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the resulting controller to simulate a trajectory. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = ampc.simulate(controller, init_obs=np.array([1.0, 0.0, 0.0, 0.0]), max_steps=200, dynamics=benchmark.dynamics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoupled Tuning\n",
    "\n",
    "The above examples is full pipeline tuning, which searches the configuration space of all components simultaneously.  Alternatively, we can take a decoupled tuning approach, where the model is first tuned based on prediction accuracy, then the objective function and optimizer are tuned.\n",
    "\n",
    "First, we must tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autompc.tuning import ModelTuner\n",
    "from autompc.evaluation import HoldoutModelEvaluator\n",
    "\n",
    "model_evaluator = HoldoutModelEvaluator(holdout_prop=0.25, metric=\"rmse\", trajs=trajs, system=system,\n",
    "                                       rng=np.random.default_rng(100))\n",
    "model_tuner = ModelTuner(system, model_evaluator)\n",
    "model_tuner.add_model_factory(model_factory)\n",
    "\n",
    "model, model_tune_result = model_tuner.run(rng=np.random.default_rng(100), n_iters=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have tuned the model, we can create a pipeline with the pre-tuned model, and then run pipeline tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_fixed_model = ampc.Pipeline(system, model, ctrlr_factory, cost_factory)\n",
    "controller2, tune_result2 = tuner.run(pipeline_fixed_model, task, trajs, n_iters=100, rng=np.random.default_rng(100), \n",
    "                                   truedyn=benchmark.dynamics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

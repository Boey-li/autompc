{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoMPC Demo\n",
    "\n",
    "Welcome!  This notebook demonstrates the core features of AutoMPC.\n",
    "\n",
    "AutoMPC is designed to simplify the process of creating a controller for a robot system with unknown dynamics.\n",
    "A standard approach to solving this problem is 1) use a System ID algorithm to produce a model of the system dynamics\n",
    "from data, 2) design an objective which captures the task you want to solve, 3) use an optimization algorithm to solve for a control sequence with respect  to the model and objective function.  AutoMPC provides a toolbox of algorithms for  all three steps, and automates the process of hyperparameter selection for each component.\n",
    "\n",
    "In this notebook, we will use the cart-pole swing-up task as an example.  Although we know the ground truth dynamics for the cart-pole system, we will demonstrate how to work with an unknown dynamical system by using a multi-layer perceptron (MLP) to learn the dynamics from data.  We will design our model predictive controller using a standard quadratic objective function and an iterative LQR optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-Up\n",
    "\n",
    "First, we will import the autompc library and other necessary dependancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading AutoMPC...\n",
      "Finished loading AutoMPC\n"
     ]
    }
   ],
   "source": [
    "import autompc as ampc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benchmarks module provides some tools for quickly building example problems.  For a list of available benchmarks, see [here](https://autompc.readthedocs.io/en/latest/source/benchmarks.html#available-benchmarks).  Here we will import the cart-pole benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autompc.benchmarks import CartpoleSwingupV2Benchmark\n",
    "\n",
    "benchmark = CartpoleSwingupV2Benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `system` object defines the observation and contorl dimensions of the cartpole, while the `task` defines the task we want to solve.  Here, we will just get these from the benchmark, but for more details on systems see example [1. Basics](https://github.com/williamedwards/autompc/tree/main/examples) and for more details on tasks see example [3. Controllers and Tasks](https://github.com/williamedwards/autompc/tree/main/examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get system and task specification\n",
    "system = benchmark.system\n",
    "task   = benchmark.task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a dataset of trajectories sampled from the system to use for system identification and tuning.  On a real system, we would collect these from the robot, but here we'll use another method from our benchmark to generate the dataset.  The default option is to generate trajectories using uniform random controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate benchmark dataset\n",
    "trajs = benchmark.gen_trajs(seed=100, n_trajs=500, traj_len=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benchmark also provides capabilities to visualize trajectories.  We can use this to visualize one of the trajectories in our training set.  Since the dataset was generated using uniform random controls, we see that this trajectory clearly does not accomplish the cart-pole swing-up task.  (Note: the animation may take a minute to generate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "#fig = plt.figure()\n",
    "#ax = fig.gca()\n",
    "#anim = benchmark.visualize(fig, ax, trajs[1])\n",
    "#HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to create an MPC to be tuned.  Here, we will use the most general form, AutoSelectController, which allows AutoMPC to automatically select between all of its system ID, optimization, and OCP generation algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autompc import AutoSelectController\n",
    "controller = AutoSelectController(system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the tunable hyperparameters of the controller.  Since AutoSelectController chooses between all possible models and optimizers, the hyperparameter space is quite large!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Configuration space object:\n",
       "  Hyperparameters:\n",
       "    ARX:history, Type: UniformInteger, Range: [1, 10], Default: 4\n",
       "    DirectTranscription:horizon, Type: UniformInteger, Range: [1, 30], Default: 10\n",
       "    IterativeLQR:horizon, Type: UniformInteger, Range: [5, 25], Default: 20\n",
       "    Koopman:lasso_alpha, Type: UniformFloat, Range: [1e-10, 100.0], Default: 1.0, on log-scale\n",
       "    Koopman:method, Type: Categorical, Choices: {lstsq, lasso, stable}, Default: lstsq\n",
       "    Koopman:poly_basis, Type: Categorical, Choices: {true, false}, Default: false\n",
       "    Koopman:poly_cross_terms, Type: Categorical, Choices: {false}, Default: false\n",
       "    Koopman:poly_degree, Type: UniformInteger, Range: [2, 8], Default: 3\n",
       "    Koopman:trig_basis, Type: Categorical, Choices: {true, false}, Default: false\n",
       "    Koopman:trig_freq, Type: UniformInteger, Range: [1, 8], Default: 1\n",
       "    Koopman:trig_interaction, Type: Categorical, Choices: {false}, Default: false\n",
       "    LQR:finite_horizon, Type: Categorical, Choices: {true, false}, Default: true\n",
       "    LQR:horizon, Type: UniformInteger, Range: [1, 1000], Default: 10\n",
       "    MLP:hidden_size_1, Type: UniformInteger, Range: [16, 256], Default: 128\n",
       "    MLP:hidden_size_2, Type: UniformInteger, Range: [16, 256], Default: 128\n",
       "    MLP:hidden_size_3, Type: UniformInteger, Range: [16, 256], Default: 128\n",
       "    MLP:hidden_size_4, Type: UniformInteger, Range: [16, 256], Default: 128\n",
       "    MLP:lr, Type: UniformFloat, Range: [1e-05, 1.0], Default: 0.001, on log-scale\n",
       "    MLP:n_hidden_layers, Type: Categorical, Choices: {1, 2, 3, 4}, Default: 2\n",
       "    MLP:nonlintype, Type: Categorical, Choices: {relu, tanh, sigmoid, selu}, Default: relu\n",
       "    MPPI:horizon, Type: UniformInteger, Range: [5, 30], Default: 20\n",
       "    MPPI:lmda, Type: UniformFloat, Range: [0.1, 2.0], Default: 1.0\n",
       "    MPPI:num_path, Type: UniformInteger, Range: [100, 1000], Default: 200\n",
       "    MPPI:sigma, Type: UniformFloat, Range: [0.0001, 2.0], Default: 1.0\n",
       "    QuadCostFactory:dx_F, Type: UniformFloat, Range: [0.001, 10000.0], Default: 1.0, on log-scale\n",
       "    QuadCostFactory:dx_Q, Type: UniformFloat, Range: [0.001, 10000.0], Default: 1.0, on log-scale\n",
       "    QuadCostFactory:omega_F, Type: UniformFloat, Range: [0.001, 10000.0], Default: 1.0, on log-scale\n",
       "    QuadCostFactory:omega_Q, Type: UniformFloat, Range: [0.001, 10000.0], Default: 1.0, on log-scale\n",
       "    QuadCostFactory:theta_F, Type: UniformFloat, Range: [0.001, 10000.0], Default: 1.0, on log-scale\n",
       "    QuadCostFactory:theta_Q, Type: UniformFloat, Range: [0.001, 10000.0], Default: 1.0, on log-scale\n",
       "    QuadCostFactory:u_R, Type: UniformFloat, Range: [0.001, 10000.0], Default: 1.0, on log-scale\n",
       "    QuadCostFactory:x_F, Type: UniformFloat, Range: [0.001, 10000.0], Default: 1.0, on log-scale\n",
       "    QuadCostFactory:x_Q, Type: UniformFloat, Range: [0.001, 10000.0], Default: 1.0, on log-scale\n",
       "    SINDy:poly_basis, Type: Categorical, Choices: {true, false}, Default: false\n",
       "    SINDy:poly_cross_terms, Type: Categorical, Choices: {false}, Default: false\n",
       "    SINDy:poly_degree, Type: UniformInteger, Range: [2, 8], Default: 3\n",
       "    SINDy:threshold, Type: UniformFloat, Range: [1e-05, 10.0], Default: 0.01, on log-scale\n",
       "    SINDy:time_mode, Type: Categorical, Choices: {discrete, continuous}, Default: discrete\n",
       "    SINDy:trig_basis, Type: Categorical, Choices: {true, false}, Default: false\n",
       "    SINDy:trig_freq, Type: UniformInteger, Range: [1, 8], Default: 1\n",
       "    SINDy:trig_interaction, Type: Categorical, Choices: {false}, Default: false\n",
       "    model, Type: Categorical, Choices: {MLP, SINDy, ARX, Koopman}, Default: MLP\n",
       "    ocp_factory, Type: Categorical, Choices: {QuadCostFactory}, Default: QuadCostFactory\n",
       "    optimizer, Type: Categorical, Choices: {IterativeLQR, MPPI, LQR, DirectTranscription}, Default: IterativeLQR\n",
       "  Conditions:\n",
       "    ARX:history | model == 'ARX'\n",
       "    DirectTranscription:horizon | optimizer == 'DirectTranscription'\n",
       "    IterativeLQR:horizon | optimizer == 'IterativeLQR'\n",
       "    Koopman:lasso_alpha | Koopman:method in {'lasso'}\n",
       "    Koopman:method | model == 'Koopman'\n",
       "    Koopman:poly_basis | model == 'Koopman'\n",
       "    Koopman:poly_cross_terms | Koopman:poly_basis in {'true'}\n",
       "    Koopman:poly_degree | Koopman:poly_basis in {'true'}\n",
       "    Koopman:trig_basis | model == 'Koopman'\n",
       "    Koopman:trig_freq | Koopman:trig_basis in {'true'}\n",
       "    Koopman:trig_interaction | Koopman:trig_basis in {'true'}\n",
       "    LQR:finite_horizon | optimizer == 'LQR'\n",
       "    LQR:horizon | LQR:finite_horizon in {'true'}\n",
       "    MLP:hidden_size_1 | model == 'MLP'\n",
       "    MLP:hidden_size_2 | MLP:n_hidden_layers in {'2', '3', '4'}\n",
       "    MLP:hidden_size_3 | MLP:n_hidden_layers in {'3', '4'}\n",
       "    MLP:hidden_size_4 | MLP:n_hidden_layers in {'4'}\n",
       "    MLP:lr | model == 'MLP'\n",
       "    MLP:n_hidden_layers | model == 'MLP'\n",
       "    MLP:nonlintype | model == 'MLP'\n",
       "    MPPI:horizon | optimizer == 'MPPI'\n",
       "    MPPI:lmda | optimizer == 'MPPI'\n",
       "    MPPI:num_path | optimizer == 'MPPI'\n",
       "    MPPI:sigma | optimizer == 'MPPI'\n",
       "    QuadCostFactory:dx_F | ocp_factory == 'QuadCostFactory'\n",
       "    QuadCostFactory:dx_Q | ocp_factory == 'QuadCostFactory'\n",
       "    QuadCostFactory:omega_F | ocp_factory == 'QuadCostFactory'\n",
       "    QuadCostFactory:omega_Q | ocp_factory == 'QuadCostFactory'\n",
       "    QuadCostFactory:theta_F | ocp_factory == 'QuadCostFactory'\n",
       "    QuadCostFactory:theta_Q | ocp_factory == 'QuadCostFactory'\n",
       "    QuadCostFactory:u_R | ocp_factory == 'QuadCostFactory'\n",
       "    QuadCostFactory:x_F | ocp_factory == 'QuadCostFactory'\n",
       "    QuadCostFactory:x_Q | ocp_factory == 'QuadCostFactory'\n",
       "    SINDy:poly_basis | model == 'SINDy'\n",
       "    SINDy:poly_cross_terms | model == 'SINDy'\n",
       "    SINDy:poly_degree | SINDy:poly_basis in {'true'}\n",
       "    SINDy:threshold | model == 'SINDy'\n",
       "    SINDy:time_mode | model == 'SINDy'\n",
       "    SINDy:trig_basis | model == 'SINDy'\n",
       "    SINDy:trig_freq | SINDy:trig_basis in {'true'}\n",
       "    SINDy:trig_interaction | SINDy:trig_basis in {'true'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controller.get_config_space()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have initialized the pipeline and its factories, we can set up a tuner to automatically search over the pipeline's configuration space.  Since we assume we don't have access to the ground truth dynamics, we train a surrogate dynamics model, which is used as a simulator to evaluate configurations.\n",
    "\n",
    "Here we pass an `MLP` instance to the tuner to be used to train the surrogate dynamics model.  The `surrogate_split` controls what proportion of the data will be used for training the surrogate dynamics model vs trainin gthe system ID model.\n",
    "\n",
    "This is an example of full pipeline which searches the configuration space of all pipeline components simultaneously.  (NOTE: This takes quite a while to run.  Skip this cell and run the next one instead to load a cached result)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/pyparsing.py:1745: FutureWarning: Possible set intersection at position 3\n",
      "  self.re = re.compile( self.reString )\n"
     ]
    }
   ],
   "source": [
    "from autompc.tuning import ControlTuner\n",
    "from autompc.sysid import MLP\n",
    "\n",
    "tuner = ControlTuner(surrogate=MLP(system), surrogate_split=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run the tuning porcess.  In addition to the pipeline, we pass the task and the trajectory dataset.  The task specification is used to evaluate the trajectories simulated with the surrogate dynamics model.  AutoMPC uses the `smac3` package for Bayesian optimization to search the configuration space.\n",
    "\n",
    "Here, we pass the ground truth dynamics to the tuner so that we can measure the true performance over time.  However, we would not have this for a real robot, so it's not used for selecting the configuration.\n",
    "\n",
    "**Note:** The tuning process can take 5 or more hours to run depending on the hardware available.  To load a cached result instead of running this yourself, skip this cell and run the next one instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william/.local/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:16<00:00,  1.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding unsupported scenario options: {'save_results_instantly': True}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Target Algorithm returned NaN or inf as quality. Algorithm run is treated as CRASHED, cost is set to 2147483647.0 for quality scenarios. (Change value through \"cost_for_crash\"-option.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CfgRunner: Exception during evaluation\n",
      "Exit code:  1\n",
      "100%|██████████| 50/50 [01:19<00:00,  1.58s/it]\n"
     ]
    }
   ],
   "source": [
    "tuned_controller, tune_result = tuner.run(controller, task, trajs, n_iters=2, rng=np.random.default_rng(100), \n",
    "                                   truedyn=benchmark.dynamics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below cell to load a cached tune result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autompc.tuning.pipeline_tuner'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6339007753b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../assets/cached_tunes/cartpole_tune_result.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtune_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0minc_cfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtune_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minc_cfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcontroller\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrajs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'autompc.tuning.pipeline_tuner'"
     ]
    }
   ],
   "source": [
    "import os, pickle\n",
    "current_folder = globals()['_dh'][0]\n",
    "fn = os.path.join(current_folder, \"../assets/cached_tunes/cartpole_tune_result.pkl\")\n",
    "with open(fn, \"rb\") as f:\n",
    "    tune_result = pickle.load(f)\n",
    "inc_cfg = tune_result.inc_cfg\n",
    "controller, cost, model = pipeline(inc_cfg, task, trajs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then plot the performance of the best controller found so far over the iterations of the tuning process.  We plot both the performance as evaluated with the surrogate dynamics and the true dynamics performance.  Lower scores are better, so after 100 iterations, both the surrogate and true performance converge to a good solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autompc.graphs import TuningCurveGraph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "graph = TuningCurveGraph()\n",
    "\n",
    "fig = plt.figure()      \n",
    "ax = fig.gca()\n",
    "graph(ax, tune_result)\n",
    "ax.set_title(\"Cart-Pole Tuning Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our tuning process has given us a controller, we can run it to simulate a trajectory.  For more information on how to work with controllers, see example [3. Controllesr ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = ampc.simulate(controller, init_obs=benchmark.task.get_init_obs(), max_steps=200, dynamics=benchmark.dynamics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "anim = benchmark.visualize(fig, ax, traj)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoupled Tuning\n",
    "\n",
    "The above examples is full pipeline tuning, which searches the configuration space of all components simultaneously.  Alternatively, we can take a decoupled tuning approach, where the model is first tuned based on prediction accuracy, then the objective function and optimizer are tuned.  Since full pipeline tuning requires us to train a system ID model and simulate the controller at every iteration, decoupled tuning may produce faster tuning.\n",
    "\n",
    "First, we'll need to handle the data split between system ID training set and surrogate training set manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(100)\n",
    "trajs_to_split = rng.permutation(trajs)\n",
    "surr_trajs = trajs_to_split[:250]\n",
    "sysid_trajs = trajs_to_split[250:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a model evaluator.  Here, we use the `HoldoutModelEvaluator` which creates a holdout set on which to train model prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autompc.evaluation import HoldoutModelEvaluator\n",
    "\n",
    "model_evaluator = HoldoutModelEvaluator(holdout_prop=0.25, metric=\"rmse\", horizon=20, trajs=trajs, \n",
    "                                        system=system, rng=np.random.default_rng(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can instantiate a model tuner and run 50 iterations of tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autompc.tuning import ModelTuner\n",
    "\n",
    "model_tuner = ModelTuner(system, model_evaluator)\n",
    "model_tuner.add_model_factory(model_factory)\n",
    "\n",
    "model, model_tune_result = model_tuner.run(rng=np.random.default_rng(100), n_iters=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have tuned the system ID model, we can create a pipeline which fixes the model.  By passing a `Model` instance instead of of a `ModelFactory`, the pipeline will treat the model as fixed, and contains only the configuration sapce for the controller and cost factories.  The same thing can be done with the controller and cost factories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_fixed_model = ampc.Pipeline(system, model, ctrlr_factory, cost_factory)\n",
    "pipeline_fixed_model.get_configuration_space()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now tune our pipeline in a similar fashion to above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner2 = PipelineTuner(surrogate_factory=MLPFactory(system), surrogate_split=1.0)\n",
    "\n",
    "controller2, tune_result2 = tuner.run(pipeline_fixed_model, task, surr_trajs, n_iters=50, \n",
    "                                      rng=np.random.default_rng(100), truedyn=benchmark.dynamics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can plot the tuning curve of our decoupled tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autompc.graphs import TuningCurveGraph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "graph = TuningCurveGraph()\n",
    "\n",
    "fig = plt.figure()      \n",
    "ax = fig.gca()\n",
    "graph(ax, tune_result2)\n",
    "ax.set_title(\"Cart-Pole Decoupled Tuning Curve\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

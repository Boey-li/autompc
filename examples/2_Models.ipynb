{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "This notebook will demonstrate the basic features of AutoMPC for system ID modeling and model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-Up\n",
    "\n",
    "As before, we begin by importing autompc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading AutoMPC...\n",
      "Finished loading AutoMPC\n"
     ]
    }
   ],
   "source": [
    "import autompc as ampc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform system identification, we need a dataset of trajectories to work with.  We will use the cartpole system, available from the `benchmarks` package, to generate our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autompc.benchmarks.mcube_pushing import MCubePushingBenchmark\n",
    "\n",
    "benchmark = MCubePushingBenchmark()\n",
    "\n",
    "system = benchmark.system\n",
    "trajs = benchmark.get_trajs(num_trajs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import some useful utilities for debugging, as well.  Here, we'll plot one of the training trajectories and some statistics about the overall training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ModelTuneResult' from 'autompc.tuning.model_tuner' (/home/william/proj/autompc_0.2-dev/autompc/tuning/model_tuner.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-30610432d89f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautompc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msysid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_model_rmse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mautompc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraphs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_traj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplot_traj_projected\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplot_simulation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplot_rollout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplot_trajs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/proj/autompc_0.2-dev/autompc/graphs/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mkstep_graph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKstepPredAccGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtuning_graph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_tuning_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_tuning_correlations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtrajectory_graph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_traj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplot_traj_projected\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplot_rollout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplot_simulation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplot_trajs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplot_trajs_projected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/proj/autompc_0.2-dev/autompc/graphs/tuning_graph.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_tuner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mControlTunerResult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_tuner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelTuneResult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_tuning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ModelTuneResult' from 'autompc.tuning.model_tuner' (/home/william/proj/autompc_0.2-dev/autompc/tuning/model_tuner.py)"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from autompc.sysid.metrics import get_model_rmse\n",
    "from autompc.graphs import plot_traj,plot_traj_projected,plot_simulation,plot_rollout,plot_trajs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(14,5))\n",
    "\n",
    "plot_traj(trajs[0],ax=ax1)\n",
    "#plot_traj_projected(trajs[0],ax=ax1)\n",
    "ax1.set_ylim(-10,10)\n",
    "plot_trajs(trajs,style='confidence',ax=ax2)\n",
    "ax2.set_ylim(-10,10)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To double-check that the dynamics are working, let's simulate a zero-control trajectory from 45 degrees tilt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from autompc import Trajectory\n",
    "from autompc.utils import rollout\n",
    "from autompc.benchmarks.cartpole import cartpole_simp_dynamics\n",
    "from autompc.graphs import plot_traj,plot_traj_projected,plot_simulation,plot_rollout,plot_trajs\n",
    "\n",
    "traj = Trajectory.zeros(system,100)\n",
    "traj.obs[0,0] = np.pi/16\n",
    "traj.ctrls[:] = 10\n",
    "\n",
    "plot_rollout(traj,benchmark.dynamics,compare=False)\n",
    "plt.ylim(-6,6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "AutoMPC provides a variety of sytem ID models which can be used to learn the sytem dynamics.  Here, we will use an Multi-Layer Perceptron (MLP) neural network model, but for a complete list see [here](https://autompc.readthedocs.io/en/latest/source/sysid.html#supported-system-id-models).\n",
    "\n",
    "You can examine the hyperparameters used for training using `get_config()` and change them using `set_hyper_values()`, as shown below.  Here we'll change batch normalization to false and the number of hidden layers in the neural net.\n",
    "\n",
    "(**Note:** This will take several minutes to run depending on your hardware)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from autompc.sysid import MLP\n",
    "\n",
    "model = MLP(system,n_train_iters=50)\n",
    "print(\"Original hyperparameter configuration\")\n",
    "print(model.get_config())                    #prints the hyperparameters of the model\n",
    "model.set_hyper_values(batchnorm=False)      #modifies the hyperparameters\n",
    "model.set_hyper_values(n_hidden_layers='3')  #modifies the hyperparameters\n",
    "print(\"Modified hyperparameter configuration\")\n",
    "print(model.get_config())                    #prints the hyperparameters of the model\n",
    "\n",
    "assert model.is_trained == False\n",
    "model.train(trajs)                           #performs training\n",
    "assert model.is_trained == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When manually training models like this, it is a good idea to inspect your training and testing error. You can do so with some convenience methods in AutoMPC.  The below code will compute the Root-Mean-Squared Error (RMSE) and also plot a rollout of the model, using the initial state and controls from a sample trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MLP 1-step RMSE on training set:\",get_model_rmse(model,trajs))\n",
    "print(\"MLP 1-step RMSE on testing set:\",get_model_rmse(model,test_trajs))\n",
    "\n",
    "plot_rollout(trajs[0],model)\n",
    "plt.ylim([-20,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained our model, we can use it to make predictions.  Let's try predicting the next state from one of our training trajectories.  We first compute the model state at a certain point in the trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = trajs[0]\n",
    "model_state = model.traj_to_state(traj[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model state contains the information the model needs to predict the next time step.  `model_state[:system.obs_dim]` is always equal to the most recent observation.  For the MLP, that's actually all there is to the model state, but some models require a larger state.  We can see the dimension of the model state by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check other properties of the model, such as whether it is differentiable and whether it is linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model is Differentiable? \", model.is_diff)\n",
    "print(\"Model is Linear? \", model.is_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, consider the ARX model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autompc.sysid import ARX\n",
    "\n",
    "model_arx = ARX(system)\n",
    "model_arx.train(trajs)\n",
    "\n",
    "print(\"ARX 1-step RMSE on training set:\",get_model_rmse(model_arx,trajs))\n",
    "print(\"ARX 1-step RMSE on testing set:\",get_model_rmse(model_arx,test_trajs))\n",
    "\n",
    "plot_rollout(trajs[0],model_arx)\n",
    "plt.ylim([-20,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that, unlike the MLP model, the ARX model state size is larger than `system.obs_dim` since the model state includes the history of several observations.  Make sure to use the `traj_to_state` method to properly derive the model state.  We can also observe that the ARX model is linear, which means that it is suitable for use with LQR control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_arx = model_arx.traj_to_state(traj[:100])\n",
    "model_arx.state_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arx.is_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our current model state, and the control to make a prediction of the new model state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_state = model.pred(model_state, traj[99].ctrl)\n",
    "pred_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to the true observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj[100].obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the true observation to update our model state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_state = model.update_state(model_state, traj[99].ctrl, traj[100].obs)\n",
    "new_model_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For differentiable models, we can also get the Jacobian of the\n",
    "model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_state, state_jac, ctrl_jac = model.pred_diff(model_state, traj[99].ctrl)\n",
    "state_jac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphing Model Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'd like to compare ARX to our original model.  One convenient way to do this is by graphing the model prediction error over various prediction horizons.  AutoMPC provides tools for easily constructing this graph.  (**Note:** This may take a few minutes to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from autompc.graphs import KstepPredAccGraph\n",
    "\n",
    "graph = KstepPredAccGraph(system, trajs, kmax=20, metric=\"rmse\")\n",
    "graph.add_model(model, \"MLP\")\n",
    "graph.add_model(model_arx, \"ARX\")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "graph(fig, ax)\n",
    "ax.set_title(\"Comparison of models\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the MLP has much lower prediction error than the ARX, and that the prediction error of both models increases with the horizon.  Here the system timestep is 0.05s, so the end of the plot is about 1 second in the future.\n",
    "\n",
    "Another thing that we often like to do is to compare the rollouts of two methods. We can do so using the `plot_traj` method multiple times on the trajectory prediction error, as shown below. It can be seen that ARX does a better job in very long-term prediction particularly on the x and dx observations, whereas MLP does a better job on short-range prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute rollout errors\n",
    "from autompc.utils import rollout\n",
    "\n",
    "index = 3\n",
    "#dims = ['x']\n",
    "dims = None\n",
    "traj_mlp = rollout(model,trajs[index])\n",
    "traj_arx = rollout(model_arx,trajs[index])\n",
    "mlp_err = traj_mlp-trajs[index]\n",
    "arx_err = traj_arx-trajs[index]\n",
    "plot_traj(mlp_err,obs_opts=[{'label':'MLP '+x} for x in traj_mlp.system.observations],ctrl_opts=False,dims=dims)\n",
    "plot_traj(arx_err,obs_opts=[{'label':'ARX '+x,'linestyle':'--'} for x in traj_arx.system.observations],ctrl_opts=False,dims=dims)\n",
    "plt.title(\"Rollout errors\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute data set of errors and plot stats for both models\n",
    "errs_mlp = [None]*len(trajs)\n",
    "errs_arx = [None]*len(trajs)\n",
    "for i in range(len(trajs)):\n",
    "    errs_mlp[i] = rollout(model,trajs[i])-trajs[i]\n",
    "    errs_arx[i] = rollout(model_arx,trajs[i])-trajs[i]\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(14,5))\n",
    "\n",
    "plot_trajs(errs_mlp,style='confidence',ctrl_opts=False,ax=ax1)\n",
    "plot_trajs(errs_arx,style='confidence',ctrl_opts=False,ax=ax2)\n",
    "ax1.set_title(\"MLP errors\")\n",
    "ax2.set_title(\"ARX errors\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
